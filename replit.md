# Overview

The Restaurant Ingredient Tracker is a Streamlit-based web application designed to help restaurants analyze their ingredient usage, waste, and costs. The application processes multiple CSV data sources (ingredient information, stock received, usage, and waste) to calculate key metrics including shrinkage, cost breakdowns, and provide comprehensive reporting capabilities with PDF and Excel export functionality.

## Recent Changes
- **CRITICAL BUG FIX**: Fixed Flask PDF export error caused by Unicode bullet character "â€¢" not supported by default Arial font - replaced with dash "-" characters for compatibility
- **CRITICAL BUG FIX**: Fixed Flask 500 error after CSV upload caused by column name mismatch between templates ('shrinkage_cost') and DataFrame ('Shrinkage Cost') - added normalize_sort_column() function to handle parameter mapping
- **CRITICAL BUG FIX**: Fixed Flask "load sample data" function that was returning 500 error due to incorrect file path references (using '../sample_*.csv' instead of 'sample_*.csv')
- **Documentation Unification**: Created comprehensive cross-linked documentation system across entire repository with navigation between all guides
- Completely reworked and enhanced the application architecture
- Fixed all LSP diagnostics and code quality issues 
- Added comprehensive data validation (duplicates, negatives, empty data)
- Enhanced PDF reports with better formatting and pagination support
- Improved Excel exports with percentages, insights, and timestamps
- Added advanced filtering and sorting options for results analysis
- Integrated sample data functionality for easy testing and demonstration
- Added smart insights and warnings for high waste/shrinkage percentages
- Updated README.md with comprehensive documentation of all new features
- Improved error handling and user experience throughout the application
- Corrected shrinkage calculation to show dollar value of missing/stolen inventory
- Updated filtering to focus on shrinkage > $10 as most important metric for tracking
- Modified default sorting to prioritize shrinkage cost analysis
- Added visual highlighting system for easy identification of problematic items
- Implemented alert system for high shrinkage items and missing stock notifications
- Added color-coded rows (red for high shrinkage, orange for missing stock)
- Enhanced UX with warning and info notice boxes for immediate issue identification
- Implemented Replit Auth integration with automatic authentication in Replit environment
- Added smart environment detection (Replit vs local/demo mode)
- Maintained demo accounts for non-Replit environments with fallback authentication
- Included seamless user experience with zero-config authentication on Replit platform
- Added comprehensive navigation system with multi-page layout (Dashboard, Analytics, Reports, Settings)
- Created enhanced login landing page with feature overview and improved UX
- Implemented sidebar navigation with logout button and user information
- Added quick stats dashboard with key metrics overview
- Separated analytics into dedicated page with advanced filtering and sorting
- Created dedicated reports page with export functionality and summary statistics
- Added settings page with help information and data management options
- Enhanced logout functionality with complete session state cleanup
- Improved responsive design with expanded sidebar configuration
- Implemented enterprise-grade Replit Auth with ReplitAuth class
- Added automatic authentication detection and session management
- Created comprehensive authentication flow with troubleshooting features
- Enhanced user experience with seamless Replit platform integration
- Added authentication status display and user session information
- Integrated Firebase, Google Cloud Identity Platform security infrastructure
- Added fraud prevention and global scalability features through enterprise auth system
- Created comprehensive Docker deployment with CPU compatibility solutions
- Fixed "Illegal instruction (core dumped)" error for SSE4a-only processors
- Added three Docker configurations: standard, simplified, and CPU-compatible
- Implemented source compilation for NumPy/Pandas to avoid AVX/SSE4.1 dependencies
- Created automated deployment scripts with error handling and troubleshooting
- Updated all documentation with local installation guides for Ubuntu, Windows, macOS
- Added complete deployment documentation with production-ready configurations
- **NEW: Created complete Flask Migration for universal hosting compatibility**
- Built Flask-based alternative with identical functionality but better hosting support
- Added professional HTML templates with Bootstrap styling and responsive design
- Implemented modular architecture with separate utilities for data processing and authentication
- Created comprehensive deployment documentation with platform-specific guides
- Added automated setup, startup, and deployment scripts for easy installation
- Implemented systemd service configuration for production Linux deployments
- Created service management script with health checks and monitoring capabilities
- Added Nginx reverse proxy configuration with SSL/HTTPS support
- Included Docker and Docker Compose configurations for containerized deployment
- Added support for multiple hosting platforms (Heroku, DigitalOcean, AWS, shared hosting)
- Maintained all original features: CSV processing, analytics, PDF/Excel reports, authentication

# User Preferences

Preferred communication style: Simple, everyday language.

# System Architecture

## Dual Frontend Architecture
- **Primary Framework**: Streamlit web framework for rapid development and testing
- **Production Framework**: Flask web framework for universal hosting compatibility
- **Layout**: Responsive Bootstrap-based design with professional styling
- **Authentication**: Dual auth system - Replit Auth for Replit environment, demo accounts for standalone
- **User Interface**: HTML forms for CSV uploads, Bootstrap tables for data display, download buttons for reports
- **Navigation**: Multi-page routing system (Dashboard, Analytics, Reports, Settings, Upload)
- **Session Management**: Flask sessions with secure cookie handling and automatic cleanup

## Flask Migration Benefits
- **Universal Hosting**: Compatible with shared hosting, VPS, cloud platforms, and containers
- **Better Performance**: Faster startup times (< 5 seconds vs 30+ seconds) and lower memory usage
- **Standard Protocols**: Uses only HTTP/HTTPS, no WebSocket dependencies
- **Production Ready**: Includes systemd service, Nginx configuration, and monitoring tools

## Data Processing Architecture
- **Data Input**: Multiple CSV file upload system supporting:
  - Ingredient information with unit costs
  - Input stock with received quantities
  - Usage data with consumed amounts
  - Waste data with wasted quantities
- **Data Validation**: CSV structure validation ensuring required columns are present
- **Data Transformation**: Pandas-based data processing with indexed merging and metric calculations
- **Calculations Engine**: Automated computation of:
  - Expected use (used + wasted)
  - Shrinkage (stocked - expected use)
  - Cost breakdowns (used cost, waste cost, shrinkage cost)
  - Total cost analysis

## Export System
- **PDF Generation**: FPDF library for creating formatted PDF reports
- **Excel Export**: XlsxWriter for generating structured Excel spreadsheets
- **Report Formatting**: Structured output with summary totals and detailed breakdowns

## Data Flow
1. CSV files uploaded through Streamlit interface
2. Data validation ensures structural integrity
3. Pandas processing merges and calculates metrics
4. Results displayed in interactive tables
5. Export functionality generates downloadable reports

# External Dependencies

## Core Libraries
- **Streamlit**: Web application framework for the user interface
- **Pandas**: Data manipulation and analysis library for CSV processing
- **FPDF**: PDF generation library for report creation
- **XlsxWriter**: Excel file generation for spreadsheet exports

## Data Format Dependencies
- **CSV Structure**: Requires specific column naming conventions:
  - Ingredient info: 'Ingredient', 'Unit Cost'
  - Input stock: 'Ingredient', 'Received Qty'
  - Usage data: 'Ingredient', 'Used Qty'
  - Waste data: 'Ingredient', 'Wasted Qty'

## Runtime Environment
- **Python Environment**: Requires Python with scientific computing stack
- **File I/O**: Local file system access for CSV uploads and report downloads
- **Memory Management**: In-memory data processing for multiple DataFrame operations